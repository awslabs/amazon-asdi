# This deploys the pipeline for building and deploying updated dask container images
# It depends on the dask ECS environment being created first
Parameters:
  DaskWorkerGitToken:
    Type: String
    Description: GitHub OAuth Token for accessing the Dask worker repository
    MinLength: 40
    AllowedPattern: "[a-zA-Z0-9_]+"
    NoEcho: true

  DaskWorkerGitSourceRepo:
    Type: String
    Description: GitHub Repository for building the container image for the Dask workers
    Default: amazon-asdi

  DaskWorkerGitHubOrg:
    Type: String
    Description: GitHub organization for Dask Worker repository
    Default: awslabs

  DaskWorkerGitSourceBranch:
    Type: String
    Description: GitHub Repository Branch for Dask workers
    Default: main

  CodeBuildDockerImage:
    Type: String
    Default: aws/codebuild/standard:5.0

  DaskClusterName:
    Type: String
    Default: 'None'
    Description: Name of the ECS cluster to deploy into

  DaskWorkerServiceName:
    Type: String
    Default: Dask-Worker
    Description: Name of the dask worker ECS service

  DaskSchedulerServiceName:
    Type: String
    Default: Dask-Scheduler
    Description: Name of the dask scheduler ECS service

Conditions:
  BuildOnlyPipeline: !Equals [!Ref DaskClusterName, 'None']
  DeployToECSPipeline: !Not [!Condition BuildOnlyPipeline]

Resources:
  CodePipelineArtifactBucket:
    Type: AWS::S3::Bucket
    DeletionPolicy: Delete

  CleanBucketOnDelete:
    DependsOn: CleanBucketOnDeleteLambda
    Type: Custom::CleanBucket
    Properties:
      ServiceToken: 
        Fn::GetAtt: 
          - "CleanBucketOnDeleteLambda"
          - "Arn"
      BucketName: !Ref CodePipelineArtifactBucket

  CleanBucketOnDeleteLambda:
    DependsOn: CodePipelineArtifactBucket
    Type: "AWS::Lambda::Function"
    Properties:
      Code: 
        ZipFile: 
          !Sub |
            import json, boto3, logging
            import cfnresponse
            logger = logging.getLogger()
            logger.setLevel(logging.INFO)
    
            def lambda_handler(event, context):
                logger.info("event: {}".format(event))
                try:
                    bucket = event['ResourceProperties']['BucketName']
                    logger.info("bucket: {}, event['RequestType']: {}".format(bucket,event['RequestType']))
                    if event['RequestType'] == 'Delete':
                        s3 = boto3.resource('s3')
                        bucket = s3.Bucket(bucket)
                        for obj in bucket.objects.filter():
                            logger.info("delete obj: {}".format(obj))
                            s3.Object(bucket.name, obj.key).delete()
    
                    sendResponseCfn(event, context, cfnresponse.SUCCESS)
                except Exception as e:
                    logger.info("Exception: {}".format(e))
                    sendResponseCfn(event, context, cfnresponse.FAILED)
    
            def sendResponseCfn(event, context, responseStatus):
                responseData = {}
                responseData['Data'] = {}
                cfnresponse.send(event, context, responseStatus, responseData, "CustomResourcePhysicalID")            
    
      Handler: "index.lambda_handler"
      Runtime: python3.7
      MemorySize: 128
      Timeout: 60
      Role : !GetAtt CleanBucketOnDeleteLambdaRole.Arn

  CleanBucketOnDeleteLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service:
            - lambda.amazonaws.com
          Action:
          - sts:AssumeRole
      Path: "/"
      Policies:
      - PolicyName: !Join ['-', [!Ref 'AWS::StackName', 'CleanBucketOnDeleteLambdaPolicy'] ]
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: Allow
            Action:
            - s3:ListBucket
            - s3:DeleteObject
            Resource:
            - !GetAtt CodePipelineArtifactBucket.Arn
            - !Join
              - "/"
              - - !GetAtt CodePipelineArtifactBucket.Arn
                - "*"
          - Effect: Deny
            Action:
            - s3:DeleteBucket
            Resource: '*'
          # - Effect: Allow
          #   Action:
          #   - logs:CreateLogGroup
          #   - logs:CreateLogStream
          #   - logs:PutLogEvents
          #   Resource: '*'

  CodeBuildServiceRole:
    Type: AWS::IAM::Role
    Properties:
      Path: /
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service: codebuild.amazonaws.com
            Action: sts:AssumeRole
      Policies:
        - PolicyName: root
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Resource:
                  Fn::GetAtt:
                    - CodeBuildLogs
                    - Arn
                Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
              - Resource: "*"
                Effect: Allow
                Action:
                  - ec2:CreateNetworkInterface
                  - ec2:DescribeDhcpOptions
                  - ec2:DescribeNetworkInterfaces
                  - ec2:DeleteNetworkInterface
                  - ec2:DescribeSubnets
                  - ec2:DescribeSecurityGroups
                  - ec2:DescribeVpcs
                  - ec2:CreateNetworkInterfacePermission
                  - ecr:GetAuthorizationToken
              - Resource: !Sub arn:aws:s3:::${CodePipelineArtifactBucket}/*
                Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:PutObject
                  - s3:GetObjectVersion
              - Resource: !GetAtt EcrDockerRepository.Arn
                Effect: Allow
                Action:
                  - ecr:GetDownloadUrlForLayer
                  - ecr:BatchGetImage
                  - ecr:BatchCheckLayerAvailability
                  - ecr:PutImage
                  - ecr:InitiateLayerUpload
                  - ecr:UploadLayerPart
                  - ecr:CompleteLayerUpload

  
  CodeBuildLogs:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: !Sub /aws/codebuild/${AWS::StackName}
      RetentionInDays: 3
    UpdateReplacePolicy: Delete
    DeletionPolicy: Delete

  # By default, the build specification is defined in this template, but you can also add buildspec.yml
  # files in your repos to allow for customization.
  # See:
  # https://docs.aws.amazon.com/codebuild/latest/userguide/build-spec-ref.html
  # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-codebuild-project-source.html
  CodeBuildProject:
    DependsOn: CodeBuildLogs
    Type: AWS::CodeBuild::Project
    Properties:
      Artifacts:
        Type: CODEPIPELINE
      Source:
        Type: CODEPIPELINE
        BuildSpec: !Sub
          - |
            ---
            version: 0.2
            phases:
              install:
                commands:
                  - nohup /usr/local/bin/dockerd --host=unix:///var/run/docker.sock --host=tcp://127.0.0.1:2375 --storage-driver=overlay2&
                  - timeout 15 sh -c "until docker info; do echo .; sleep 1; done"
              pre_build:
                  commands:
                  - printenv
                  - TAG="$REPOSITORY_NAME.$REPOSITORY_BRANCH.$(date +%Y-%m-%d.%H.%M.%S).$(echo $CODEBUILD_RESOLVED_SOURCE_VERSION | head -c 8)"
                  - echo $TAG
                  - aws ecr get-login-password --region "$REGION" | docker login --username AWS --password-stdin "$ACCOUNT_ID.dkr.ecr.$REGION.amazonaws.com"
              build:
                commands:
                  - cd examples/dask-worker && docker build --tag $REPOSITORY_URI:$TAG --tag $REPOSITORY_URI:latest . && cd ../..
              post_build:
                commands:
                  - docker push $REPOSITORY_URI:$TAG
                  - docker push $REPOSITORY_URI:latest
                  - printf '[{"name":"${ServiceName}","imageUri":"%s"}]' $REPOSITORY_URI:$TAG > build.json
            artifacts:
              files: build.json
          - ServiceName: Dask
      Environment:
        ComputeType: BUILD_GENERAL1_SMALL
        Type: LINUX_CONTAINER
        PrivilegedMode: True
        Image: !Ref CodeBuildDockerImage
        EnvironmentVariables:
          - Name: ACCOUNT_ID
            Value: !Sub ${AWS::AccountId}
          - Name: REGION
            Value: !Sub ${AWS::Region}
          - Name: REPOSITORY_URI
            Value: !Sub ${AWS::AccountId}.dkr.ecr.${AWS::Region}.amazonaws.com/${EcrDockerRepository}
          - Name: REPOSITORY_NAME
            Value: !Ref DaskWorkerGitSourceRepo
          - Name: REPOSITORY_BRANCH
            Value: !Ref DaskWorkerGitSourceBranch
      Name: !Ref AWS::StackName
      ServiceRole: !Ref CodeBuildServiceRole

  CodePipelineServiceRole:
    Type: AWS::IAM::Role
    Properties:
      Path: /
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service: codepipeline.amazonaws.com
            Action: sts:AssumeRole
      Policies:
        - PolicyName: codepipeline-access
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Resource: "*"
                Effect: Allow
                Action:
                  - ecs:List*
                  - ecs:Describe*
                  - ecs:RegisterTaskDefinition
                  - ecs:UpdateService
                  - codebuild:StartBuild
                  - codebuild:BatchGetBuilds
                  - codecommit:GetBranch
                  - codecommit:GetCommit
                  - codecommit:UploadArchive
                  - codecommit:GetUploadArchiveStatus
                  - codecommit:CancelUploadArchive
                  - iam:PassRole
              - Resource: !Sub arn:aws:s3:::${CodePipelineArtifactBucket}/*
                Effect: Allow
                Action:
                  - s3:PutObject
                  - s3:GetObject
                  - s3:GetObjectVersion
                  - s3:GetBucketVersioning
              - Resource: !Sub ${NotifyWaitConditionLambdaFunction.Arn}
                Effect: Allow
                Action:
                  - lambda:InvokeFunction
                  - lambda:InvokeAsync
    DependsOn:
      - CodePipelineArtifactBucket

  # This CodePipeline triggers on a commit to the Git branch passed, builds the Docker image
  # and then deploys the container in the Fargate Cluster.
  CodePipelineGitHub:
    Type: AWS::CodePipeline::Pipeline
    Properties:
      RoleArn: !GetAtt CodePipelineServiceRole.Arn
      ArtifactStore:
        Type: S3
        Location: !Ref CodePipelineArtifactBucket
      Stages:
        - Name: Source
          Actions:
            - Name: App
              ActionTypeId:
                Category: Source
                Owner: ThirdParty
                Version: 1
                Provider: GitHub
              Configuration:
                Owner: !Ref DaskWorkerGitHubOrg
                Repo: !Ref DaskWorkerGitSourceRepo
                Branch: !Ref DaskWorkerGitSourceBranch
                OAuthToken: !Ref DaskWorkerGitToken
              OutputArtifacts:
                - Name: App
              RunOrder: 1
        - Name: Build
          Actions:
            - Name: Build
              ActionTypeId:
                Category: Build
                Owner: AWS
                Version: 1
                Provider: CodeBuild
              Configuration:
                ProjectName: !Ref CodeBuildProject
              InputArtifacts:
                - Name: App
              OutputArtifacts:
                - Name: BuildOutput
              RunOrder: 1
        - Fn::If:
            - DeployToECSPipeline
            - Name: Deploy
              Actions:
                - Name: DeployScheduler
                  ActionTypeId:
                    Category: Deploy
                    Owner: AWS
                    Version: 1
                    Provider: ECS
                  Configuration:
                    ClusterName: !Ref DaskClusterName
                    ServiceName: !Ref DaskSchedulerServiceName
                    FileName: build.json
                  InputArtifacts:
                    - Name: BuildOutput
                  RunOrder: 1
                - Name: DeployWorker
                  ActionTypeId:
                    Category: Deploy
                    Owner: AWS
                    Version: 1
                    Provider: ECS
                  Configuration:
                    ClusterName: !Ref DaskClusterName
                    ServiceName: !Ref DaskWorkerServiceName
                    FileName: build.json
                  InputArtifacts:
                    - Name: BuildOutput
                  RunOrder: 2
            - !Ref "AWS::NoValue"
        - Name: Notify
          Actions:
            - Name: NotifyCloudformation
              ActionTypeId:
                Category: Invoke
                Owner: AWS
                Version: "1"
                Provider: Lambda
              Configuration:
                FunctionName: !Ref NotifyWaitConditionLambdaFunction
              RunOrder: 1
          
    DependsOn:
      - CodePipelineArtifactBucket
      - CodeBuildProject
      - CodePipelineServiceRole

  DeployWaitHandle:
    Type: AWS::CloudFormation::WaitConditionHandle

  DeployWaitCondition:
    Type: AWS::CloudFormation::WaitCondition
    Properties:
      Count: 1
      Handle: !Ref DeployWaitHandle
      Timeout: "900"
  
  NotifyWaitConditionLambdaFunction:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.handler
      Role: !GetAtt LambdaNotifyRole.Arn
      Code:
        ZipFile: !Sub |
          import json
          import boto3
          import json
          import urllib.request
          code_pipeline = boto3.client('codepipeline')
          cfn = boto3.client('cloudformation')
          def handler(event, context):
            job_id = event['CodePipeline.job']['id']
            url = '${DeployWaitHandle}'
            headers = { "Content-Type": "" }
            try:
              cfn_response = cfn.describe_stacks(
                StackName='${AWS::StackName}'
              )
              print("response: " + json.dumps(cfn_response, default=str))
              stack_status = cfn_response['Stacks'][0]['StackStatus']
              if stack_status == 'CREATE_IN_PROGRESS':
                data = { "Status": "SUCCESS", "Reason": "Compilation Succeeded", "UniqueId": "Dask", "Data": "Compilation Succeeded" }
                req = urllib.request.Request(url, headers=headers, data=bytes(json.dumps(data), encoding="utf-8"), method='PUT')
                response = urllib.request.urlopen(req)
              code_pipeline.put_job_success_result(jobId=job_id)
            except Exception as e:
              print("failure: " + str(e))
              code_pipeline.put_job_failure_result(jobId=job_id, failureDetails={'message': str(e), 'type': 'JobFailed'})
      Runtime: python3.7
      Timeout: 10
  
  LambdaNotifyRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
        - Effect: Allow
          Principal:
            Service:
            - lambda.amazonaws.com
          Action:
          - sts:AssumeRole
      Path: /
      Policies:
      - PolicyName: root
        PolicyDocument:
          Version: 2012-10-17
          Statement:
          - Resource: "*"
            Effect: Allow
            Action:
              - codepipeline:PutJobSuccessResult
              - codepipeline:PutJobFailureResult
              - cloudformation:DescribeStacks
          - Effect: Allow
            Action:
              - logs:CreateLogGroup
              - logs:CreateLogStream
              - logs:PutLogEvents
            Resource: '*'

  EcrDockerRepository:
    Type: AWS::ECR::Repository

  CleanECROnDelete:
    DependsOn: CleanECROnDeleteLambda
    Type: Custom::CleanECR
    Properties:
      ServiceToken: 
        Fn::GetAtt: 
          - "CleanECROnDeleteLambda"
          - "Arn"
      RepositoryName: !Ref EcrDockerRepository

  CleanECROnDeleteLambda:
    DependsOn: EcrDockerRepository
    Type: "AWS::Lambda::Function"
    Properties:
      Code: 
        ZipFile: 
          !Sub |
            import json, boto3, logging
            import cfnresponse
            logger = logging.getLogger()
            logger.setLevel(logging.INFO)
    
            def lambda_handler(event, context):
                logger.info("event: {}".format(event))
                try:
                    repo = event['ResourceProperties']['RepositoryName']
                    logger.info("bucket: {}, event['RequestType']: {}".format(repo,event['RequestType']))
                    if event['RequestType'] == 'Delete':
                        client = boto3.client('ecr')
                        resp = client.list_images(repositoryName=repo)
                        if 'imageIds' in resp:
                          images = resp['imageIds']
                          image_ids = [imageDigest for imageDigest in images]
                          if len(image_ids) > 0:
                            client.batch_delete_image(repositoryName=repo, imageIds=image_ids)
    
                    sendResponseCfn(event, context, cfnresponse.SUCCESS)
                except Exception as e:
                    logger.info("Exception: {}".format(e))
                    sendResponseCfn(event, context, cfnresponse.FAILED)
    
            def sendResponseCfn(event, context, responseStatus):
                responseData = {}
                responseData['Data'] = {}
                cfnresponse.send(event, context, responseStatus, responseData, "CustomResourcePhysicalID")            
    
      Handler: "index.lambda_handler"
      Runtime: python3.7
      MemorySize: 128
      Timeout: 60
      Role : !GetAtt CleanECROnDeleteLambdaRole.Arn

  CleanECROnDeleteLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service:
            - lambda.amazonaws.com
          Action:
          - sts:AssumeRole
      Path: "/"
      Policies:
      - PolicyName: !Join ['-', [!Ref 'AWS::StackName', 'CleanECROnDeleteLambdaPolicy'] ]
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: Allow
            Action:
              - ecr:ListImages
              - ecr:batchDeleteImage
            Resource: !GetAtt EcrDockerRepository.Arn
          # - Effect: Allow
          #   Action:
          #   - logs:CreateLogGroup
          #   - logs:CreateLogStream
          #   - logs:PutLogEvents
          #   Resource: '*'

Outputs:
  ECRRepositoryName:
    Description: Name of the ECR repository that contains the dask container image
    Value: !Sub ${AWS::AccountId}.dkr.ecr.${AWS::Region}.amazonaws.com/${EcrDockerRepository}
