{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing ERA5 data in NetCDF Format\n",
    "\n",
    "This notebook demonstrates how to work with the ECMWF ERA5 reanalysis available as part of the AWS Public Dataset Program (https://registry.opendata.aws/ecmwf-era5/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook utilizes Amazon SageMaker & AWS Fargate for providing an environment with a Jupyter notebook and Dask cluster. There is an example AWS CloudFormation template available at https://github.com/awslabs/amazon-asdi/tree/main/examples/dask for quickly creating this environment in your own AWS account to run this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import boto3\n",
    "import botocore\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import s3fs\n",
    "import fsspec\n",
    "import dask\n",
    "from dask.distributed import performance_report, Client, progress\n",
    "\n",
    "font = {'family' : 'sans-serif',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 18}\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install graphviz\n",
    "#import graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale out Dask Workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecs = boto3.client('ecs')\n",
    "resp = ecs.list_clusters()\n",
    "clusters = resp['clusterArns']\n",
    "if len(clusters) > 1:\n",
    "    print(\"Please manually select your cluster\")\n",
    "cluster = clusters[0]\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to update the `--cluster` option in the comamnd below to make your cluster name from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numWorkers=48\n",
    "ecs.update_service(cluster=cluster, service='Dask-Worker', desiredCount=numWorkers)\n",
    "ecs.get_waiter('services_stable').wait(cluster=cluster, services=['Dask-Worker'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the Dask Client to talk to our Fargate Dask Distributed Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client('Dask-Scheduler.local-dask:8786')\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following will identify the public IP address of the Dask-Scheduler task (based on security group membership) and output the dashboard URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec2 = boto3.client('ec2')\n",
    "resp = ec2.describe_network_interfaces(\n",
    "  Filters=[{\n",
    "      'Name': 'group-name',\n",
    "      'Values': ['DaskSchedulerSecurityGroup']\n",
    "  }])\n",
    "schedulerurl = 'http://' + resp['NetworkInterfaces'][0]['Association']['PublicDnsName'] + ':8787/status'\n",
    "from IPython.core.display import display,HTML\n",
    "display(HTML('Dask scheduler URL: <a href=\\'' + schedulerurl + '\\'>' + schedulerurl + '</a>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open an Example File and Check the Native Chunking\n",
    "\n",
    "We want to chunk in a similar way for maximum performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = s3fs.S3FileSystem(anon=True)\n",
    "fs.ls('era5-pds/2020/01/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 's3://era5-pds/2010/01/data/air_temperature_at_2_metres.nc'\n",
    "ncfile = fsspec.open(url)\n",
    "ds = xr.open_dataset(ncfile.open())\n",
    "\n",
    "ds.air_temperature_at_2_metres.encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.air_temperature_at_2_metres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ds size in GB {:0.2f}\\n'.format(ds.nbytes / 1e9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open 2-m air temperature as a single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = 2015\n",
    "end_year = 2020\n",
    "years = list(np.arange(start_year, end_year+1, 1))\n",
    "months = [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"]\n",
    "file_pattern = 's3://era5-pds/{year}/{month}/data/air_temperature_at_2_metres.nc'\n",
    "\n",
    "@dask.delayed\n",
    "def s3open(path):\n",
    "    fs = s3fs.S3FileSystem(anon=True, default_fill_cache=False)\n",
    "    return fs.open(path)\n",
    "\n",
    "files_mapper = [s3open(file_pattern.format(year=year,month=month)) for year in years for month in months]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ds = xr.open_mfdataset(files_mapper, engine='h5netcdf', chunks={'lon':400,'lat':200,'time0':720}, concat_dim='time0', combine='nested', coords='minimal', compat='override', parallel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ds size in GB {:0.2f}\\n'.format(ds.nbytes / 1e9))\n",
    "ds.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ds.info` output above shows us that there are four dimensions to the data: lat, lon, and time0; and two data variables: air_temperature_at_2_metres, and air_pressure_at_mean_sea_level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.air_temperature_at_2_metres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert units to C from K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['air_temperature_at_2_metres'] = (ds.air_temperature_at_2_metres - 273.15)\n",
    "ds.air_temperature_at_2_metres.attrs['units'] = 'C'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the mean 2-m air temperature for all times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the mean along the time dimension\n",
    "temp_mean = ds['air_temperature_at_2_metres'].mean(dim='time0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expressions above didnâ€™t actually compute anything. They just build the dask task graph. To do the computations, we call the `persist` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp_mean.data.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_mean = temp_mean.persist()\n",
    "progress(temp_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Average Surface Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_mean.compute()\n",
    "temp_mean.plot(figsize=(30, 15))\n",
    "plt.title('2015-2020 Mean 2-m Air Temperature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat for standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_std = ds['air_temperature_at_2_metres'].std(dim='time0')\n",
    "temp_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_std = temp_std.persist()\n",
    "progress(temp_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_std.compute()\n",
    "temp_std.plot(figsize=(30, 15))\n",
    "plt.title('2015-2020 Standard Deviation 2-m Air Temperature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot temperature time series for points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location coordinates\n",
    "locs = [\n",
    "    {'name': 'Santa Barbara', 'lon': -119.70, 'lat': 34.42},\n",
    "    {'name': 'Colorado Springs', 'lon': -104.82, 'lat': 38.83},\n",
    "    {'name': 'Honolulu', 'lon': -157.84, 'lat': 21.29},\n",
    "    {'name': 'Seattle', 'lon': -122.33, 'lat': 47.61},\n",
    "    {'name': 'Melbourne', 'lon': 144.95, 'lat': -37.84},\n",
    "]\n",
    "\n",
    "# convert westward longitudes to degrees east\n",
    "for l in locs:\n",
    "    if l['lon'] < 0:\n",
    "        l['lon'] = 360 + l['lon']\n",
    "locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_locs = xr.Dataset()\n",
    "air_temp_ds = ds\n",
    "\n",
    "# interate through the locations and create a dataset\n",
    "# containing the temperature values for each location\n",
    "for l in locs:\n",
    "    name = l['name']\n",
    "    lon = l['lon']\n",
    "    lat = l['lat']\n",
    "    var_name = name\n",
    "\n",
    "    ds2 = air_temp_ds.sel(lon=lon, lat=lat, method='nearest')\n",
    "\n",
    "    lon_attr = '%s_lon' % name\n",
    "    lat_attr = '%s_lat' % name\n",
    "\n",
    "    ds2.attrs[lon_attr] = ds2.lon.values.tolist()\n",
    "    ds2.attrs[lat_attr] = ds2.lat.values.tolist()\n",
    "    ds2 = ds2.rename({'air_temperature_at_2_metres' : var_name}).drop(('lat', 'lon'))\n",
    "\n",
    "    ds_locs = xr.merge([ds_locs, ds2])\n",
    "\n",
    "ds_locs.data_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_locs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f = ds_locs.to_dataframe()\n",
    "df_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot temperature timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_f.plot(figsize=(30, 15), title=\"ERA5\", grid=1)\n",
    "ax.set(xlabel='Date', ylabel='2-m Air Temperature (deg F)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster scale down\n",
    "\n",
    "When we are temporarily done with the cluster we can scale it down to save on costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numWorkers=0\n",
    "ecs.update_service(cluster=cluster, service='Dask-Worker', desiredCount=numWorkers)\n",
    "ecs.get_waiter('services_stable').wait(cluster=cluster, services=['Dask-Worker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_daskpy3",
   "language": "python",
   "name": "conda_daskpy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
